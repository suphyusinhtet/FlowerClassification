# -*- coding: utf-8 -*-
"""Classification of Flowers using CNN and Transfer Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QcTkUPxyeSSSNXonq0I67UfFCXOWyCJ8
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES
# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = ':https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F8782%2F2431805%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240911%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240911T130909Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D06fc133f5758bdf867a77dfc2fbe00e052f3240fdfa193d198b22e4e0e7dd1288b1f67cd1d9594bcfee028fe18f8cd047d366fc2cd0878f825dbb13fe1ac78a95974bd17437ad1d9d914d4bd591da2c682cc34eea6ff5a8973e52c04c80e43577722c0fafb80370f63020f979c74e711aebf19dec16e4333f917ad932fd8793d1a524944967ba83bfbf314d4641633d1a0ff5c8d299d11a4f338727d77c69c7ce0ff8ffc5a32f9fa10cfe661377b1dab372a9e183b3437e11ca691cd32ba6f65c106e9b8d5462f4e2b570e9fdf9dde24d3961642b6e3b8c88a5b71b266bda0361bf6697f48a6cf22d564c61d8a3998f19ab40c145d0f41a5fbfc66e16e75c3c2'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')

"""# Flower Classification Using CNN and Transfer Learning ðŸŒ¸

## Overview ðŸŒŸ

Welcome to the Flower Classification Project! This initiative is centered on using convolutional neural networks (CNN) and transfer learning techniques to predict the types of flowers from images. We will work with advanced models like MobileNetV2 and Xception to classify flowers based on their unique features, aiming for high accuracy and performance.

## Objectives ðŸŽ¯

- Develop a CNN model specifically for flower classification.
- Apply transfer learning with pre-trained architectures (MobileNetV2, Xception).
- Train, fine-tune, and evaluate models to ensure precise flower classification.
- Compare the performance between CNN and transfer learning methods.

## Structure ðŸ“

### 1. Project Introduction
   - A brief overview of the projectâ€™s purpose and goals.
   - Explanation of CNN and transfer learning for image classification tasks, particularly flower recognition.

### 2. Dataset Overview ðŸ“Š
   - A detailed look at the dataset being used for flower classification.
   - Information about the various flower classes present in the dataset.

### 3. Data Preparation ðŸ› ï¸
   - Steps for loading, cleaning, and preparing the flower image data.
   - Explanation of image augmentation and the pipeline setup.

### 4. CNN Architecture ðŸ¤–
   - Detailed architecture of the custom CNN model.
   - Discussion on training, validation, and testing phases.

### 5. Transfer Learning Models ðŸš€
   - Introduction to transfer learning using pre-trained models such as MobileNetV2 and Xception.
   - Process of fine-tuning these models for flower classification.

### 6. Model Evaluation ðŸ“Š
   - Evaluation using metrics like accuracy, precision, recall, and F1-score.
   - Comparative analysis of the custom CNN and transfer learning models.

### 7. Results and Insights ðŸ“ˆ
   - Examination of the model performance results.
   - Key observations from the comparison of different models and their behavior on the dataset.

### 8. Conclusion ðŸŒŸ
   - Summary of findings, including the strengths and weaknesses of each model.
   - Potential improvements and future steps for enhancing model accuracy or deployment.

## Tools and Technologies ðŸ’»

- Python for scripting and model development.
- TensorFlow and Keras libraries for deep learning.
- Matplotlib and Seaborn for visualizing data and results.
- Kaggle Notebooks for development and execution.
- Powered by Kaggleâ€™s P100 GPU accelerator for faster training.

This project will explore the power of CNNs and transfer learning, highlighting how both approaches can be used to effectively classify images of flowers.

# CONTENT

# 1. IMPORTINGS
"""

import os
import pandas as pd
import tensorflow as tf
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.image import imread

"""# 2. READ IMAGES"""

path = "/kaggle/input/flowers"

os.listdir(path)

os.listdir(path+'/tulip')[:10]

class_names = ['daisy','dandelion',  'rose', 'sunflower', 'tulip']

input_shape = (256,256)

for flower_class in class_names:
    class_path = os.path.join(path, flower_class)
    max_values = []
    min_values = []
    for image in os.listdir(class_path):
        img = imread(os.path.join(class_path, image))
        max_val = img.max()
        min_val = img.min()
        max_values.append(max_val)
        min_values.append(min_val)
    max_class_val = max(max_values)
    min_class_val = min(min_values)
    print("***************************")
    print(f"Class: {flower_class}")
    print(f"Max value: {max_class_val}")
    print(f"Min value: {min_class_val}")

print("***************************")

"""So you can see data is not scaled

# 3. TRAIN-VALIDATION SPLIT
"""

batch_size = 64

train_ds = tf.keras.utils.image_dataset_from_directory(
  path,
  validation_split=0.2,
  subset="training",
  seed=123,
  image_size=input_shape,
  batch_size=batch_size)

val_ds = tf.keras.utils.image_dataset_from_directory(
  path,
  validation_split=0.2,
  subset="validation",
  seed=123,
  image_size=input_shape,
  batch_size=batch_size)

"""See different split techniques at : https://www.kaggle.com/code/eneskosar19/image-classification-pipeline-tensorflow"""

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
  for i in range(15):
    ax = plt.subplot(3, 5, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")

"""# 3.1. CACHE AND PREFETCH

![applsci-13-04436-g002.png](attachment:b2e3f298-4d48-4a20-bf1e-009dfb12f697.png)
"""

AUTOTUNE = tf.data.AUTOTUNE

train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

"""1. **Caching**: Stores data in memory after first load (both training and validation). This dramatically reduces disk access time, significantly speeding up training, especially for large datasets.

2. **Shuffling** (training only): Randomizes data order to prevent overfitting. This helps the model learn general patterns from the data, leading to better performance on unseen examples.
  
3. **Prefetching with Autotune** (both): Overlaps data prep with model training, using optimal buffer size based on your hardware. This hides data processing latency, allowing the model to work continuously and potentially reducing training time.

# 4. SCALING

**Importance of Data Set Scaling**
Data set scaling is a crucial step in TensorFlow that can significantly speed up model training. Especially when working with large datasets, this process can dramatically impact the model's convergence time and overall performance.

**Benefits of Scaling:**

1. Faster Training: Scaling can significantly reduce training time by increasing the model's access and processing speed of the dataset. This leads to faster results and shorter development cycles.
2. Enhanced Performance: A proper scaling strategy can optimize overall performance by helping the model learn patterns in the dataset more efficiently.
3. Memory Efficiency: Data set scaling can help the model occupy less memory, which is crucial especially when working with large datasets.
4. Overall Resource Optimization: Proper scaling can ensure more efficient use of CPU, GPU, and other hardware resources, optimizing overall system performance.
"""

train_ds = train_ds.map(lambda x,y: (x/255, y))
val_ds = val_ds.map(lambda x,y: (x/255, y))

image_batch, labels_batch = next(iter(train_ds)) #This is how you read image batches, each batch contains 64 images and 64 related labels

first_image = image_batch[0]

print(np.min(first_image), np.max(first_image))

"""Now it's scaled

# 5.1 CREATE MODEL
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout,BatchNormalization

input_shape =  (256,256,3) #Add extra dimension "3" because it represent RGB(Colored Image)

num_classes = len(class_names)
num_classes

model = Sequential()

model.add(Conv2D(16, (3,3), padding='same', activation='relu', input_shape=input_shape))
model.add(MaxPooling2D())
model.add(Conv2D(32, (3,3), padding='same', activation='relu'))
model.add(MaxPooling2D())
model.add(Conv2D(64, (3,3), padding='same', activation='relu'))
model.add(MaxPooling2D())
model.add(Conv2D(64, (3,3), padding='same', activation='relu'))
model.add(MaxPooling2D())

model.add(Flatten())
#ANN

model.add(Dense(64, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))

"""# 5.2 COMPILE"""

model.compile('adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])

model.summary()

"""# 5.3 FIT

Let's get the insights about the model
"""

history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=10
)

"""![overfitting-and-underfitting-wrt-model-error-vs-complexity.png](attachment:4ada7acb-7bc8-49aa-bb7e-e76ee53d5985.png)

# 5.4 INSIGHTS AFTER FIRST FIT

1. While accuracy increasing , val_accuracy started to decrease  -> Maybe Overfitting ??

2. While loss is decreasing , val_loss started to increase --> Overfitting ??

3. After a while, the difference between train and validation started to get bigger --> OVERFIT

What is overfitting,you can basically say that model tries to memorize instead of learning, so train scores are too high,test scores will be to low.
Model will mispredict the datas which it didn't see.

See detailed description here : https://www.tensorflow.org/tutorials/keras/overfit_and_underfit

# 5.5 VISUALIZE THE TRAIN RESULTS
"""

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(10)

plt.figure(figsize=(12, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='upper left')
plt.title('Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper left')
plt.title('Loss')
plt.show()

"""So we can see it's overfit while val_los is increasing,train_los is decrease

# 6. DEAL WITH OVERFITTING

How to deal with overfitting ?

To combat overfitting in deep learning, we have several powerful techniques:

**Data Augmentation:** This artificially expands the training data by creating variations of existing data (e.g., rotating images, adding noise). This exposes the model to a wider range of scenarios, improving its ability to generalize to unseen data and reducing overfitting.

**Batch Normalization:** This stabilizes the training process by normalizing the activations of hidden layers, making the model less sensitive to initialization values and allowing for faster learning.

**Early Stopping:** This technique monitors the model's performance on a validation set. If the validation performance stops improving, training is halted to prevent the model from memorizing irrelevant details in the training data.

**Dropout:** This injects randomness by randomly dropping out neurons during training. This forces the model to learn robust features that are not dependent on any specific neuron, ultimately reducing overfitting.


See more techniques here : https://towardsdatascience.com/8-simple-techniques-to-prevent-overfitting-4d443da2ef7d

See detailed augmentation tutorial here : https://medium.com/ymedialabs-innovation/data-augmentation-techniques-in-cnn-using-tensorflow-371ae43d5be9

We will not be using data augmentation because it is increasing data and fit time, but you can try

# 6.1 DROPOUT - BATCH NORMALIZATION
"""

from tensorflow.keras.optimizers import Adam

model = Sequential()


model.add(Conv2D(16, (3,3), padding='same', activation='relu', input_shape=(256,256,3)))
model.add(MaxPooling2D())
model.add(Conv2D(32, (3,3), padding='same', activation='relu'))
model.add(MaxPooling2D())
model.add(Dropout(0,2))
model.add(Conv2D(64, (3,3), padding='same', activation='relu'))
model.add(MaxPooling2D())
model.add(Conv2D(128, (3,3), padding='same', activation='relu'))
model.add(MaxPooling2D())
model.add(Conv2D(256, (3,3), padding='same', activation='relu'))
model.add(MaxPooling2D())

model.add(Flatten())
#ANN

model.add(Dense(64, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0,2))
model.add(Dense(32, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))

model.compile(optimizer=Adam(learning_rate=0.003),
              loss=tf.keras.losses.SparseCategoricalCrossentropy(),
              metrics=['accuracy'])

model.summary()

"""# 6.2 REDUCE LEARNING RATE"""

batch_size=64

from keras.callbacks import ReduceLROnPlateau
red_lr= ReduceLROnPlateau(monitor='val_accuracy',patience=3,verbose=1,factor=0.1)

class GetBestModel(tf.keras.callbacks.Callback):
    def __init__(self, monitor = "val_loss", verbose = 0, mode = "auto"):
        super(GetBestModel, self).__init__()
        self.monitor = monitor
        self.verbose = verbose
        self.mode = mode
        if self.mode == "min":
            self.best = np.Inf
        else:
            self.best = -np.Inf

    def on_epoch_end(self, epoch, logs=None):
        current = logs.get(self.monitor)
        if self.mode == "min" and current < self.best:
            self.best = current
            self.best_weights = self.model.get_weights()
        elif self.mode == "max" and current > self.best:
            self.best = current
            self.best_weights = self.model.get_weights()

    def on_train_end(self, logs=None):
        self.model.set_weights(self.best_weights)

best_model = GetBestModel(monitor = "val_loss", mode = "min", verbose = 1)

"""# 6.3 EARLY STOPPING"""

from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(monitor='val_loss',patience=5)

epochs = 25
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs,
  batch_size=batch_size,
  callbacks=[early_stop,red_lr,best_model]
)

pd.DataFrame(history.history).plot();

model.save('my_trained_model.h5')

"""# 7. TRANSFER LEARNÄ°NG"""

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications import Xception

"""**Transfer Learning**

Transfer learning is a technique in deep learning where a pre-trained model on one task is leveraged to improve performance on a new, but related task. It's like having a seasoned student help a new student learn the ropes.

We use transfer learning because it offers several advantages:

**Faster Training:** Training a complex model from scratch can be time-consuming and require a massive amount of data. Transfer learning allows you to utilize the knowledge already captured in the pre-trained model, significantly reducing training time.
**Better Performance:** Pre-trained models are often trained on vast datasets, giving them a strong understanding of underlying concepts. By transferring this knowledge, you can achieve better results on your new task, even with a limited dataset.
**Reduced Resources:** Training complex models requires significant computational power. Transfer learning allows you to leverage the pre-trained model, reducing the computational resources needed for your new task.

**Overall**, transfer learning is a powerful tool that accelerates the development of machine learning models and improves their performance, making it a valuable technique in various applications.

![1_ZkPBqU8vx2vAgcLpz9pi5g.jpg](attachment:89db1ec6-8d04-42ec-9997-1c2e85b99331.jpg)

# 7.1 Xception Model

See detailed source : https://www.tensorflow.org/api_docs/python/tf/keras/applications/Xception
"""

pretrained_model.output_shape
num_classes

from tensorflow.keras.applications import Xception
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, Input
from tensorflow.keras.optimizers import Adam
import tensorflow as tf


# Define input
input_tensor = Input(shape=(256, 256, 3))

# Load pre-trained Xception model without top layers
pretrained_model = Xception(include_top=False,
                            input_tensor=input_tensor,
                            pooling='avg',
                            weights='imagenet')

# Freeze the layers of the pre-trained model
for layer in pretrained_model.layers:
    layer.trainable = False

# Add ANN layers
x = pretrained_model.output
x = Dense(512, activation='relu')(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.2)(x)

# Final classification layer
output_tensor = Dense(num_classes, activation='softmax')(x)

# Define the model
Xception_model = Model(inputs=input_tensor, outputs=output_tensor)

# Compile the model
Xception_model.compile(optimizer=Adam(learning_rate=0.003),
                       loss=tf.keras.losses.SparseCategoricalCrossentropy(),
                       metrics=['accuracy'])

# Print the summary of the model
Xception_model.summary()

"""layer.trainable=False

**This code freezes the weights of all layers in the pre-trained model, preventing them from being updated during training.**
"""

Xception_model_results = Xception_model.fit(train_ds, epochs=25,
                             validation_data=val_ds,
                             callbacks=[early_stop])

Xception_model.save('Xception_trained_model.h5')

"""# 7.2 MobileNetV2 Model

See detailed source : https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v2
"""

early_stop = EarlyStopping(monitor='val_loss',patience=20) #increased the patience of early stoping

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, Input
from tensorflow.keras.optimizers import Adam
import tensorflow as tf

# Define the input shape explicitly
input_tensor = Input(shape=(256, 256, 3))

# Load pre-trained MobileNetV2 model without the top layers
pretrained_model = MobileNetV2(include_top=False,
                               input_tensor=input_tensor,
                               pooling='avg',  # Global average pooling is applied
                               weights='imagenet')

# Freeze the layers of the pre-trained model
for layer in pretrained_model.layers:
    layer.trainable = False

# Create the output of the pre-trained model
x = pretrained_model.output

# Add ANN layers
x = Dense(512, activation='relu')(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.2)(x)  # Correct dropout rate
x = Dense(32, activation='relu')(x)

# Final classification layer
output_tensor = Dense(num_classes, activation='softmax')(x)

# Define the full model
MobileNetV2_model = Model(inputs=input_tensor, outputs=output_tensor)

# Compile the model
MobileNetV2_model.compile(optimizer=Adam(learning_rate=0.003),
                          loss=tf.keras.losses.SparseCategoricalCrossentropy(),
                          metrics=['accuracy'])

# Print the summary of the model
MobileNetV2_model.summary()

MobileNetV2_model_results = MobileNetV2_model.fit(train_ds, epochs=50,
                             validation_data=val_ds,
                             callbacks=[early_stop])

MobileNetV2_model.save('MobileNetV2_trained_model.h5')

"""# 8. COMPARISON - VISUALIZE THE TRAINING RESULTS"""

# Plotting accuracy
plt.plot(Xception_model_results.history['accuracy'], label='Xception_model (Train)')
plt.plot(Xception_model_results.history['val_accuracy'], label='Xception_model (Val)')
plt.plot(MobileNetV2_model_results.history['accuracy'], label='MobileNetV2_model (Train)')
plt.plot(MobileNetV2_model_results.history['val_accuracy'], label='MobileNetV2_model (Val)')
plt.plot(history.history['accuracy'], label='Your CNN Model (Train)')
plt.plot(history.history['val_accuracy'], label='Your CNN Model (Val)')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy Comparison')
plt.legend()
plt.show()

# Plotting loss
plt.plot(Xception_model_results.history['loss'], label='Xception_model (Train)')
plt.plot(Xception_model_results.history['val_loss'], label='Xception_model (Val)')
plt.plot(MobileNetV2_model_results.history['loss'], label='MobileNetV2_model (Train)')
plt.plot(MobileNetV2_model_results.history['val_loss'], label='MobileNetV2_model (Val)')
plt.plot(history.history['loss'], label='Your CNN Model (Train)')
plt.plot(history.history['val_loss'], label='Your CNN Model (Val)')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss Comparison')
plt.legend()
plt.show()

"""# 9. CONCLUSION

MobileNetV2 outperforms the other models, achieving a remarkable training accuracy of 0.99 and a testing accuracy of 0.87. Xception also performs well, with a training accuracy of 0.98 and a slightly lower testing accuracy of 0.86.

On the other hand, the custom CNN model falls short, attaining a training accuracy of just 0.76 and a testing accuracy of 0.69. Despite the close training accuracy between MobileNetV2 and Xception, MobileNetV2's higher testing accuracy demonstrates its superior ability to generalize to unseen data.

**These results highlight the advantages of transfer learning, where pre-trained models like MobileNetV2 and Xception draw on knowledge from vast datasets to improve performance on specific tasks. Transfer learning not only boosts accuracy but also significantly reduces the time and computational resources needed for training, making it a powerful approach for building efficient and high-performing machine learning models.**

See all transfer learning models : https://www.tensorflow.org/api_docs/python/tf/keras/applications/

# Evaluation on Performance of Models using Manual Test Flower Image

you can upload the test manual flower image from the five type of images used in the dataset (tulip, dandelion, rose, daisy, sunflower) to test the model performance by using the saved models and loading them to classify the test image.
"""

from tensorflow.keras.models import load_model

# Load the saved model
my_trained_model = load_model('my_trained_model.h5')
MobileNetV2_trained_model = load_model('MobileNetV2_trained_model.h5')
Xception_trained_model = load_model('Xception_trained_model.h5')

import numpy as np
from tensorflow.keras.preprocessing import image

# Upload the test flower image and replace the image path
img_path = '/content/dandelion.jpg'

# Load and preprocess the image
img = image.load_img(img_path, target_size=(256, 256))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array /= 255.0  # Scale pixel values to [0, 1]

import numpy as np
from tensorflow.keras.preprocessing import image

# Upload the test flower image and replace the image path
img_path = '/content/dandelion.jpg'

# Load and preprocess the image
img = image.load_img(img_path, target_size=(256, 256))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array /= 255.0  # Scale pixel values to [0, 1]

# Make predictions
prediction_with_my_trained_model = my_trained_model.predict(img_array)
prediction_with_MobileNetV2_trained_model = MobileNetV2_trained_model.predict(img_array)
prediction_with_Xception_trained_model = Xception_trained_model.predict(img_array)

# Get the predicted class index
predicted_class_1 = np.argmax(prediction_with_my_trained_model, axis=-1)
predicted_class_2 = np.argmax(prediction_with_MobileNetV2_trained_model, axis=-1)
predicted_class_3 = np.argmax(prediction_with_Xception_trained_model, axis=-1)

# List of class names
class_names = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']

# Print the predicted class
print(f"The predicted class with my trained model is: {class_names[predicted_class_1[0]]}")
print(f"The predicted class with MobileNetV2 trained model is: {class_names[predicted_class_2[0]]}")
print(f"The predicted class with Xception trained model is: {class_names[predicted_class_3[0]]}")